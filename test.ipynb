{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14623b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import pathlib\n",
    "import torch \n",
    "import numpy as np\n",
    "import random\n",
    "import optuna\n",
    "from IPython.display import HTML\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.insert(0, str(pathlib.Path.cwd()/\"src\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.insert(0, str(pathlib.Path.cwd()/\"src\"))\n",
    "import torch \n",
    "import numpy as np\n",
    "import random\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "import pandas as pd\n",
    "from loaders.hrrr import discrete_scalar_field, discrete_vector_field\n",
    "from fields.vector_field import ContinuousVectorField\n",
    "def run_experiment(date: str, level: int):\n",
    "    dsf = discrete_scalar_field(date, hours=4, level=f\"{level} mb\", extent=(-92, -74, 26, 40))\n",
    "    cvf = ContinuousVectorField()\n",
    "    cvf.train(dsf, epochs=100, sample_size=2000)\n",
    "    dvf = discrete_vector_field(date, hours=4, level=f\"{level} mb\", extent=(-92, -74, 26, 40))\n",
    "    return {\n",
    "        \"date\": date,\n",
    "        \"level\": level,\n",
    "        \"$\\sigma^2$\": float(cvf.sigma2),\n",
    "        \"$l_0$\": float(cvf.l0),\n",
    "        \"$l_1$\": float(cvf.l1),\n",
    "        \"$l_2$\": float(cvf.l2),\n",
    "        \"RMS\": float(dvf.RMS()),\n",
    "        \"RMSE\":   float(cvf.RMSE(dvf))\n",
    "    }\n",
    "\n",
    "# 2. specify your dates, levels, and extent once\n",
    "dates  = [\"2024-03-15\", \"2024-06-21\", \"2024-09-18\", \"2024-12-25\"]\n",
    "levels = [500, 700]\n",
    "\n",
    "# 3. collect results\n",
    "results = []\n",
    "for date in dates:\n",
    "    for lvl in levels:\n",
    "        results.append(run_experiment(date, lvl))\n",
    "\n",
    "# 4. build DataFrame and export LaTeX\n",
    "df = pd.DataFrame(results)\n",
    "latex = df.to_latex(\n",
    "    index=False,\n",
    "    float_format=\"%.3f\",\n",
    "    caption=\"Estimated coveriance parameters and RMSE by date and pressure level\",\n",
    "    label=\"tab:params_rmse\"\n",
    ")\n",
    "out = pathlib.Path(__file__).parent / \"table.tex\"\n",
    "with open(out, \"w\") as f:\n",
    "    f.write(latex)\n",
    "print(f\"Wrote LaTeX table to {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe7a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F00\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "ðŸ‘¨ðŸ»â€ðŸ­ Created directory: [/home/yf297/data/hrrr/20240315]\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F01\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F02\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F03\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F04\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "Epoch 1/100 â€” Avg NLL: 0.8847\n",
      "Epoch 2/100 â€” Avg NLL: 0.8328\n",
      "Epoch 3/100 â€” Avg NLL: 0.7973\n",
      "Epoch 4/100 â€” Avg NLL: 0.7559\n",
      "Epoch 5/100 â€” Avg NLL: 0.7185\n",
      "Epoch 6/100 â€” Avg NLL: 0.6842\n",
      "Epoch 7/100 â€” Avg NLL: 0.6445\n",
      "Epoch 8/100 â€” Avg NLL: 0.6142\n",
      "Epoch 9/100 â€” Avg NLL: 0.5749\n",
      "Epoch 10/100 â€” Avg NLL: 0.5475\n",
      "Epoch 11/100 â€” Avg NLL: 0.5037\n",
      "Epoch 12/100 â€” Avg NLL: 0.4738\n",
      "Epoch 13/100 â€” Avg NLL: 0.4454\n",
      "Epoch 14/100 â€” Avg NLL: 0.4182\n",
      "Epoch 15/100 â€” Avg NLL: 0.3744\n",
      "Epoch 16/100 â€” Avg NLL: 0.3467\n",
      "Epoch 17/100 â€” Avg NLL: 0.3110\n",
      "Epoch 18/100 â€” Avg NLL: 0.2793\n",
      "Epoch 19/100 â€” Avg NLL: 0.2474\n",
      "Epoch 20/100 â€” Avg NLL: 0.2172\n",
      "Epoch 21/100 â€” Avg NLL: 0.2072\n",
      "Epoch 22/100 â€” Avg NLL: 0.1621\n",
      "Epoch 23/100 â€” Avg NLL: 0.1564\n",
      "Epoch 24/100 â€” Avg NLL: 0.1089\n",
      "Epoch 25/100 â€” Avg NLL: 0.0760\n",
      "Epoch 26/100 â€” Avg NLL: 0.0541\n",
      "Epoch 27/100 â€” Avg NLL: 0.1042\n",
      "Epoch 28/100 â€” Avg NLL: 0.0466\n",
      "Epoch 29/100 â€” Avg NLL: 0.0227\n",
      "Epoch 30/100 â€” Avg NLL: 0.0086\n",
      "Epoch 31/100 â€” Avg NLL: -0.0086\n",
      "Epoch 32/100 â€” Avg NLL: -0.0148\n",
      "Epoch 33/100 â€” Avg NLL: -0.0062\n",
      "Epoch 34/100 â€” Avg NLL: -0.0683\n",
      "Epoch 35/100 â€” Avg NLL: 0.0033\n",
      "Epoch 36/100 â€” Avg NLL: -0.0145\n",
      "Epoch 37/100 â€” Avg NLL: 0.0604\n",
      "Epoch 38/100 â€” Avg NLL: -0.0477\n",
      "Epoch 39/100 â€” Avg NLL: -0.0890\n",
      "Epoch 40/100 â€” Avg NLL: -0.0678\n",
      "Epoch 41/100 â€” Avg NLL: -0.0562\n",
      "Epoch 42/100 â€” Avg NLL: -0.0230\n",
      "Epoch 43/100 â€” Avg NLL: -0.1132\n",
      "Epoch 44/100 â€” Avg NLL: 0.0117\n",
      "Epoch 45/100 â€” Avg NLL: -0.0793\n",
      "Epoch 46/100 â€” Avg NLL: -0.0828\n",
      "Epoch 47/100 â€” Avg NLL: -0.0333\n",
      "Epoch 48/100 â€” Avg NLL: -0.0598\n",
      "Epoch 49/100 â€” Avg NLL: -0.0689\n",
      "Epoch 50/100 â€” Avg NLL: -0.0316\n",
      "Epoch 51/100 â€” Avg NLL: -0.0489\n",
      "Epoch 52/100 â€” Avg NLL: -0.0932\n",
      "Epoch 53/100 â€” Avg NLL: -0.0764\n",
      "Epoch 54/100 â€” Avg NLL: 0.0529\n",
      "Epoch 55/100 â€” Avg NLL: -0.0424\n",
      "Epoch 56/100 â€” Avg NLL: -0.0265\n",
      "Epoch 57/100 â€” Avg NLL: -0.0827\n",
      "Epoch 58/100 â€” Avg NLL: -0.0571\n",
      "Epoch 59/100 â€” Avg NLL: -0.0044\n",
      "Epoch 60/100 â€” Avg NLL: -0.0588\n",
      "Epoch 61/100 â€” Avg NLL: -0.0749\n",
      "Epoch 62/100 â€” Avg NLL: -0.1081\n",
      "Epoch 63/100 â€” Avg NLL: -0.0940\n",
      "Epoch 64/100 â€” Avg NLL: -0.0484\n",
      "Epoch 65/100 â€” Avg NLL: -0.0424\n",
      "Epoch 66/100 â€” Avg NLL: -0.0740\n",
      "Epoch 67/100 â€” Avg NLL: -0.0377\n",
      "Epoch 68/100 â€” Avg NLL: -0.1326\n",
      "Epoch 69/100 â€” Avg NLL: -0.0809\n",
      "Epoch 70/100 â€” Avg NLL: -0.1307\n",
      "Epoch 71/100 â€” Avg NLL: -0.1367\n",
      "Epoch 72/100 â€” Avg NLL: -0.1243\n",
      "Epoch 73/100 â€” Avg NLL: -0.0421\n",
      "Epoch 74/100 â€” Avg NLL: -0.1131\n",
      "Epoch 75/100 â€” Avg NLL: -0.0799\n",
      "Epoch 76/100 â€” Avg NLL: -0.0295\n",
      "Epoch 77/100 â€” Avg NLL: -0.1411\n",
      "Epoch 78/100 â€” Avg NLL: -0.0957\n",
      "Epoch 79/100 â€” Avg NLL: -0.0516\n",
      "Epoch 80/100 â€” Avg NLL: -0.1327\n",
      "Epoch 81/100 â€” Avg NLL: -0.0960\n",
      "Epoch 82/100 â€” Avg NLL: -0.1136\n",
      "Epoch 83/100 â€” Avg NLL: -0.0812\n",
      "Epoch 84/100 â€” Avg NLL: -0.0914\n",
      "Epoch 85/100 â€” Avg NLL: -0.1001\n",
      "Epoch 86/100 â€” Avg NLL: -0.1365\n",
      "Epoch 87/100 â€” Avg NLL: -0.0898\n",
      "Epoch 88/100 â€” Avg NLL: -0.0710\n",
      "Epoch 89/100 â€” Avg NLL: -0.0292\n",
      "Epoch 90/100 â€” Avg NLL: -0.1372\n",
      "Epoch 91/100 â€” Avg NLL: -0.1204\n",
      "Epoch 92/100 â€” Avg NLL: -0.0643\n",
      "Epoch 93/100 â€” Avg NLL: -0.0836\n",
      "Epoch 94/100 â€” Avg NLL: -0.0759\n",
      "Epoch 95/100 â€” Avg NLL: -0.1259\n",
      "Epoch 96/100 â€” Avg NLL: -0.0911\n",
      "Epoch 97/100 â€” Avg NLL: -0.0932\n",
      "Epoch 98/100 â€” Avg NLL: -0.0715\n",
      "Epoch 99/100 â€” Avg NLL: -0.0956\n",
      "Epoch 100/100 â€” Avg NLL: -0.1124\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F00\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F01\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F02\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F03\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F04\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F00\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F01\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F02\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F03\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "âœ… Found â”Š model=hrrr â”Š \u001b[3mproduct=sfc\u001b[0m â”Š \u001b[38;2;41;130;13m2024-Mar-15 00:00 UTC\u001b[92m F04\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m â”Š \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "Epoch 1/100 â€” Avg NLL: 0.8795\n",
      "Epoch 2/100 â€” Avg NLL: 0.8561\n",
      "Epoch 3/100 â€” Avg NLL: 0.7952\n",
      "Epoch 4/100 â€” Avg NLL: 0.7546\n",
      "Epoch 5/100 â€” Avg NLL: 0.7235\n",
      "Epoch 6/100 â€” Avg NLL: 0.6799\n",
      "Epoch 7/100 â€” Avg NLL: 0.6417\n",
      "Epoch 8/100 â€” Avg NLL: 0.6086\n",
      "Epoch 9/100 â€” Avg NLL: 0.5771\n",
      "Epoch 10/100 â€” Avg NLL: 0.5485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m dates:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lvl \u001b[38;5;129;01min\u001b[39;00m levels:\n\u001b[0;32m---> 25\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvl\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 4. build DataFrame and export LaTeX\u001b[39;00m\n\u001b[1;32m     28\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(date, level)\u001b[0m\n\u001b[1;32m      2\u001b[0m dsf \u001b[38;5;241m=\u001b[39m discrete_scalar_field(date, hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, extent\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m92\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m74\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m40\u001b[39m))\n\u001b[1;32m      3\u001b[0m cvf \u001b[38;5;241m=\u001b[39m ContinuousVectorField()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcvf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dvf \u001b[38;5;241m=\u001b[39m discrete_vector_field(date, hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, extent\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m92\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m74\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m40\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: date,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m: level,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m:   \u001b[38;5;28mfloat\u001b[39m(cvf\u001b[38;5;241m.\u001b[39mRMSE(dvf))\n\u001b[1;32m     15\u001b[0m }\n",
      "File \u001b[0;32m~/Transport/src/fields/vector_field.py:98\u001b[0m, in \u001b[0;36mContinuousVectorField.train\u001b[0;34m(self, scalar_field, epochs, sample_size)\u001b[0m\n\u001b[1;32m     95\u001b[0m flow \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mneural_flow\u001b[38;5;241m.\u001b[39mNeuralFlow()\n\u001b[1;32m     96\u001b[0m gp \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mgp\u001b[38;5;241m.\u001b[39mGP(flow)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc0\u001b[39m(TXY):\n\u001b[1;32m    101\u001b[0m     Jacobians \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvmap(torch\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39mjacrev(train\u001b[38;5;241m.\u001b[39mscale\u001b[38;5;241m.\u001b[39mScaleFlow(gp\u001b[38;5;241m.\u001b[39mflow,nt,nl,nli)))(TXY)\n",
      "File \u001b[0;32m~/Transport/src/train/optim.py:68\u001b[0m, in \u001b[0;36mmle\u001b[0;34m(T, XY, Z, gp, epochs, sample_size, nn)\u001b[0m\n\u001b[1;32m     65\u001b[0m     output \u001b[38;5;241m=\u001b[39m gp(TXY_pred)\n\u001b[1;32m     66\u001b[0m     ll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmll(output, Z_pred) \u001b[38;5;241m/\u001b[39m T_steps\n\u001b[0;32m---> 68\u001b[0m \u001b[43mll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22db7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
